# 第五讲 物理内存管理
## 5.1 计算机体系结构和内存层次
一个进程使用内存时要满足其要求，在不用时应及时回收。  
寄存器是非常小的；内存的最小访问是8bit，一次读写32位的话也要注意对齐问题。  
高速缓存如果不命中，则到内存中查找，在内存中找不到，就读取到内存中再读取，需要操作系统的介入。  
内存中每一个字节有一个物理地址，硬盘中扇区512字节最小单位，我们希望将线性的物理内存空间转换成逻辑内存空间；很好的把保护（独立地址空间）和共享（访问相同内存）结合，虚拟化（实现更大的逻辑空间）。  
操作系统中采用的内存管理：重定位（段地址+offset）、分段（希望他能够不连续，将程序分成三个相对独立的空间，代码数据加堆栈）、分页（把内存分成最基本的单位）。  
MMU（内存管理单元）

## 5.2 地址空间和地址生成
物理地址空间是硬件支持的地址空间，多少位就是有多少条地址线；逻辑地址是CPU运行时进程看到的地址，对应可执行文件中的区域，进程的逻辑地址空间需要转换成物理地址空间，最后在总线上访问相应的物理单元。  
逻辑地址生成：将程序转成汇编码，添加逻辑地址，再进行链接，把多个模块和函数库排成线性的序列，在程序加载要进行重定位，把链接时生成的地址进行平移。  
在编译时，如果已知运行时起始地址，则可以直接生成地址，如果起始地址改变则要重新编译；在加载时也可生成绝对地址，编译器生成可重定位的代码；执行时地址生成出现在使用虚拟存储的情况下，在执行指令时进行地址转换，最灵活，可以移动指令实现虚拟内存。

CPU：ALU需要逻辑地址的内存内容，MMU进行逻辑地址和内存地址的转换，CPU控制逻辑给总线发送物理地址请求，内存发送物理地址的内容给CPU，操作系统建立逻辑地址和物理地址的映射。  
CPU在执行指令时，如果访问数据段的数据，如果数据段基址+offset超过了数据段，则内存访问异常，执行失败，调用中断处理程序；如果正确那在段基址寄存器配合下得到相应的地址。  

## 5.3 连续内存分配
为了提高效率，采用动态分配算法。  
连续内存分配指给进程分配一块不小于指定大小的连续物理内存区域，会产生一些碎片，一种是两块分配单元之间的未被使用的内存，内部碎片是分配单元内部的未被使用的内存，取决于分配单元大小是否要考虑取整和对齐。  
动态分区分配是指程序加载时分配一个进程指定大小可变的分区，分配得到的地址是连续的。操作系统维护两个数据结构，一个是所有进程已分配的分区，另一个是空闲分区。动态分区分配策略有很多：  
最先匹配（从空闲分区列表里找第一个符合的，释放时检查是不是可以和邻近的空闲分区合并，在高地址有大块的空闲分区，但有很多外部碎片，分配大块时较慢）；  
最佳匹配（全找一遍，找最合适的，空闲分区按照从小往大排序，释放时跟邻近地址的合并，并且重排序，大部分分配的尺寸较小时比较好，避免大的空闲分区被拆分，减小外部碎片，但是增加了无用的小碎片）；  
最差匹配（找相差最大的，空闲分区从大到小拍，分配时找最大的，释放时检查可否与邻近的空闲分区合并，进行合并并重排序，如果中等大小的分配较多，则最好，避免出现太多小碎片，但是释放分区比较慢，容易破坏大的空闲分区）。  
## 5.4碎片整理
调整已分配的进程占用的分区位置来减少或避免分区碎片，通过移动分配给进程的内存分区，以合并外部碎片。保证所有程序可动态重定位！  
分区对换：通过抢占并回收处于等待状态进程的分区，以增大可用内存空间。采用对换使多个进程同时运行。

## 5.5 伙伴系统
连续内存分配实例。  
整个可分配的分区约定为2^U，需要的分区大小为2^(U-1) < s < 2^(U)，把整个块分配给这个进程。如s<2^(i-1)-1，将大小为2^i的当前分区划分成2个大小为2^(i-1)的空闲分区，重复划分过程，直到2^(i-1)-1<\s<2^(i)，把一个空闲分区分配给该进程。  
数据结构：空闲块按照大小和起始地址组织成二维数组，初始时只有一个大小为2^U的块，由小到大在空闲数组找最小的，如果空闲块过大，则进行二等分，直到得到需要的大小是空闲块的1/2还大些。总之，找比它大的最小的空闲块，看是不是比它的二倍大，如果是，就切块，不是的话就分配给它。合并：大小相同且地址相邻，起始地址较小的块的起始地址必须是2^(i+1)的倍数。两个块具有相同大小，且它们物理地址连续。

> 为了便于页面的维护，将多个页面组成内存块，每个内存块都有 2 的方幂个页，方幂的指数被称为阶 order。order相同的内存块被组织到一个空闲链表中。伙伴系统基于2的方幂来申请释放内存页。
当申请内存页时，伙伴系统首先检查与申请大小相同的内存块链表中，检看是否有空闲页，如果有就将其分配出去，并将其从链表中删除，否则就检查上一级，即大小为申请大小的2倍的内存块空闲链表，如果该链表有空闲内存，就将其分配出去，同时将剩余的一部分（即未分配出去的一半）加入到下一级空闲链表中；如果这一级仍没有空闲内存；就检查它的上一级，依次类推，直到分配成功或者彻底失败，在成功时还要按照伙伴系统的要求，将未分配的内存块进行划分并加入到相应的空闲内存块链表
在释放内存页时，会检查其伙伴是否也是空闲的，如果是就将它和它的伙伴合并为更大的空闲内存块，该检查会递归进行，直到发现伙伴正在被使用或者已经合并成了最大的内存块。

# 第六讲 物理内存管理: 非连续内存分配
## 6.1 非连续内存分配的需求背景
一种是段，一种是页，还有段页式。  
非连续分配的目的是提高内存利用效率和管理灵活性：
1. 允许一个程序使用非连续的物理地址空间；
2. 允许共享代码与数据；
3. 支持动态加载和动态链接。
如何实现虚拟地址和物理地址的转换？软/硬件。  

## 6.2 段式存储管理
段的地址空间是如何组织的，内存访问如何进行。
进程的地址空间看成若干个段，主代码段、子模块代码段、公用库代码段、堆栈段、初始化数据段、符号表等。段式管理更精细。把逻辑地址空间转换成一个不连续的物理地址空间集。  
每一个段是访问方式和存储数据等属性一致的一段地址空间；对应一个连续的内存块，若干个段组成了逻辑地址空间，把逻辑地址分成一个二元组（段号，段内偏移地址），再转换成原来的地址。  
程序访问物理单元时，首先用段号查段表，找到段的起始地址和长度，硬件的存储管理单元（MMU）检查越界，在MMU里利用段地址和偏移找到实际地址。  
## 6.3 页式存储管理
物理内存空间分成“帧”，大小是2的n次幂，让这个转换变得方便，逻辑地址空间里也划分成相同大小的基本分配单位“页”，页面到页帧的转换涉及了“页表”、MMU/TLB。  
物理地址组织成二元组（帧号，帧内偏移量）。逻辑地址空间也是二元组（p，o），逻辑地址中页号是连续的，物理地址的帧号是不连续的，逻辑地址中页号是p，物理地址的帧号是f，用p到页表中找对应的f，页表中保存了每个页的页表基址，用p就可以找到。每个帧的大小是2的n次方，把f左移s位再把页内偏移加上，就可以找到物理地址。  

## 6.4 页表概述
从逻辑页号到物理页号的转换，每一个逻辑页号对应一个物理帧号，且随着程序运行变化，动态调整分配给程序的内存大小。这个表存在页表基址寄存器，告诉你这个页表放在哪。页表项中有帧号f，有几个标志位：
> 存在位：如果有对应的物理帧则为1；
> 修改位：是否修改对应页面的内容；
> 引用位：在过去一段时间里是否有过引用。


内存访问性能：访问一个内存单元需要2次内存访问，先获取页表项，再访问数据。  
页表大小问题：页表可能非常大。  
处理缓存或者间接访问（一个很长的表，多级页表等）

## 6.5 快表和多级页表
快表：缓存近期访问的页表项，在TLB使用关联存储实现，查找对应的key，并行查找表项，具备快速访问性能。如果没有命中只能再次查找内存中的页表并把它加到快表中。  
多级页表：通过间接引用将页号分为k级。整个访问次数是k+1。建立页表树。先查第一段逻辑地址作为第一级页表的偏移，找到第二级页表的起始，第二段地址作为第二级页表项的偏移，找到第三级页表项的起始。就是说第一段地址是这个页在第一级页表中的偏移，第二段是这个页在第二级页表中的偏移地址。利用多级页表减少了整个页表的长度。  

## 6.6 反置页表
对于大地址空间系统，多级页表变得繁琐，让页表项和物理地址空间的大小对应，不让页表项和逻辑地址空间的大小对应。这样进程数目的增加和虚拟地址空间的增大对页表占用空间没影响。  
页寄存器：每个帧和一个页寄存器关联，寄存器里有：使用位表示此帧是否被使用；占用页号表明对应的页号p，保护位表明使用方式是读或者写。  
页寄存器中的地址转换：CPU生成的逻辑地址如何找对应的物理地址？对逻辑地址做Hash映射，并解决Hash冲突，利用快表缓存页表项，如果出现冲突，遍历所有的对应页表项，查找失败时产生异常。

## 6.7 段页式存储管理
在段式管理的基础上，给每个段加一级页表，得到段的页表，再得到页的地址。

# 第七讲 实验二 物理内存管理
## 7.1 x86保护模式的特权级
x86的特权级有0，1，2，3，一般只需要0（Kernel）和3（user），有些指令只能在ring 0中执行，CPU在某些情况下也会检查特权级。  
段选择子位于段寄存器中，程序在代码段中执行，指令执行会访问代码段和数据段。它的DPL位于段描述符中，来进行特权控制。中断门和陷入门中也有对应的DPL。产生中断和内存访问都有对应的CPL和RPL，进行检查确保当前的操作合法。 RPL处于数据段（DS或ES中最低两位），CPL处于指令代码段中（CS最低两位）。
数字越低特权级越高，数字越高特权级越低。 
DPL是要被访问的目标的特权级。访问门时代码段的CPL要小于门的DPL，门的特权级要比较低，执行代码段的特权级比较高，这样才允许通过门（中断陷入什么的）一般特权级的应用程序可以访问处于内核态的操作系统提供的服务；访问段的时候CPL和RPL中的最大值小于DPL，即发出请求的特权级要高于对应目标，DPL的特权级要比较小。

## 7.2 了解特权级切换过程
通过中断切换特权级。有一个中断门，通过中断描述符表进行切换，如果产生了中断，内核态ring 0中的栈会压入一系列东西（当前执行的程序的堆栈信息SS，ESP，EFLAGS，保存了回去的地址CS，EIP等）以便恢复现场。如何回到ring3？如果是从ring0跳到ring3的，在栈中会存SS（RPL=3）和ESP，用户的ss和内核态的ss不是同一个数据段，这是特权级的转换，内核栈把数据弹出来了。通过构造一个能返回ring3的栈，再通过iret指令把相关信息弹出栈，这时候运行环境已经变成用户态。  
从ring3到ring0的转换，建立中断门，一旦产生中断需要保存一些信息。通过对堆栈修改，使其执行完iret后留在ring0执行，修改CS使其指向内核态的代码段。  
TSS是特殊段，任务状态段，在内存中，保存了不同特权级的堆栈信息。在全局描述符表中有一个专门指向这个TSS。硬件有一个专门的寄存器缓存TSS中的内容，建立TSS是在pmm.c中。

## 7.3 了解段/页表
x86内存管理单元MMU
有一系列寄存器和段描述符，寄存器里的信息最高端的十几位作为索引来找全局描述符表（GDT）里的一项，找对应的项，一项就是一个段描述符，描述了地址和基址，base address+EIP这个offset找到最终的线性地址。 如果没有页机制的话，线性地址就是物理地址。 
MMU放在内存中，每次访问要先查找GDT（段表），靠硬件实现把建立在GDT里的段描述符的相关信息放在一些寄存器中的隐藏部分，缓存了基址和段大小等隐藏信息，放在CPU内部的。  
在entry.S中建立了映射机制，lab1建立的是对等映射，而lab2中base_address是 -0xC0000000，虚地址比线性地址大0xC0000000.只是这个用到的映射关系（放在GDT中的信息）不同。

## 7.4 了解UCORE建立段/页表
一个虚拟地址它分了三块，一个典型的二级页表是32位的地址，第一个是Offset，占了12位，中间的二级页表对应的页表项占了10位，高的页目录项也占了10位。那么高的这10位是用来作为index查找这个页目录表里面的对应的项，这叫PDE，是页目录的entry，PDE记录的是二级页表里面的起始地址。所以说根据PDE里面的信息可以找到Page Table的起始地址。同时根据第二级Table这里面的10位作为index来查这个Page Table对应的项。称之为PTE。这个PTE就是Page Table Entry。存的是这个线性地址它所对应的一个页的起始地址。这一个页大小多其实由它的Offset可以算出来，12位意味着一个页的大小是4k。base_address加上offset得到了地址。
进入保护模式后段机制一定存在，为了保护。  
根据地址的前10位找到Page Table的物理地址，中间12位找到PDE，计算物理页的基址。利用PDE和PTE加上offset算出地址。  
CR3寄存器保存了页目录地址。  CR0的31位如果置1的话就打开了页机制。
页的基址、页表的基址都是20位，剩下12位存下了一些信息（只读？用户态或内核态）    
分配一个4k的页作为页目录的Table，清理这个Page做初始化，建立页表，在页目录表和页表中填好对应信息。0xC0000000到0xF8000000这块空间会映射到物理地址的0x00000000到0x38000000这么一个地址，它的偏移值是0xC0000000，链接时用到的起始地址就是0xC0000000，把0x00000000到0x00100000映射到0x00100000的对等映射，且把CR0的31位置1，即enable了页机制，需要UPDATE GDT，使段机制的不对等映射变成对等映射，又做了取消0x00000000到0x00100000映射的操作。  
