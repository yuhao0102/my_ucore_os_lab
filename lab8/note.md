# 第二十一讲 文件系统
## 文件系统和文件
文件系统是操作系统中管理持久性数据的子系统，提供数据存储和访问功能。
- 组织、检索、读写访问数据；
- 大多数计算机系统都有文件系统；
- Google也是一个文件系统。

文件是具有符号名，由字节序列组成的数据项集合，它是文件系统的基本单位，文件名是其标识符号。

文件系统的功能：
- 分配文件磁盘空间
    - 管理文件块
    - 管理空间控件
    - 分配算法，磁盘上有很多空间块，如何选择空闲块
- 管理文件集合
    - 定位：通过文件名找到内容
    - 命名：通过名字找到文件
    - 文件系统结构：文件的组织方式
- 数据可靠与安全
    - 安全
    - 可靠：持久保存文件并在系统崩溃时恢复

文件属性：名称、类型、位置、大小、保护、创建者、创建时间等。把文件的信息分成两部分，文件头是文件系统元数据中的文件信息，文件存储位置和顺序。

## 文件描述符
读写数据之前必须打开文件。操作系统内核跟踪进程打开的文件，维护了一个打开文件表，文件描述符是打开文件的标识，程序打开文件的数目和文件系统里的数目是有量级上的区别的，所以单独设计了一个文件描述符方便设计。

操作系统在打开文件表中维护了打开文件的状态信息。
- 文件指针：最近一次读写位置，每个进程分别维护自己的打开文件指针。每个进程读写一个文件都有自己的打开文件指针。
- 文件打开计数：当前打开文件打开的次数，最后一个进程关闭这个文件指针后，这个文件就可以被从打开文件表中移除。
- 文件的磁盘位置：缓存文件的位置，下次就可以省事了
- 访问权限：可读可写？

文件的用户视图：在用户看来，它是一个持久的数据结构。

从系统来看，它是一个字节序列的集合，系统不关心存储在磁盘上的数据结构，只是看成一个数据块的集合，数据块是逻辑的存储单位，这里与扇区有区别，扇区是物理存储单元。

进程读文件时，首先获取字节所在的数据块，因为读写的时候必须是以块为单位的。然后把其中需要的内容返回给进程，写文件时，首先获取字节所在的数据块，修改数据块中的对应部分，再写回。因此文件系统的基本操作单位是数据块。例如，getc和putc即使每次只访问1字节的内容也要缓存目标块的4096字节，因此，一个可行的优化是充分利用读进来缓存的这一个块。

操作系统需要了解进程如何访问文件
- 顺序访问：按字节依次读取
- 随机访问：从中间读写，不常用，但是也很重要，例如，虚拟内存中把内存也存储在文件中。
- 索引访问：通常不提供，数据库是建立在索引内容上的磁盘访问。

文件内部结构：
- 无结构：单词、字节序列
- 简单记录结构：分列、固定长度或可变长度
- 复杂结构：格式化文档或者可执行文件等，操作系统并不关心

多用户系统中的文件共享是很重要的，但是如何进行访问控制？每个用户能够获得哪些文件的哪些权限？访问模式分为：读、写、执行、删除、列表信息等。文件访问控制列表（ACL）指明了文件实体和权限的关系

多个进程同时访问一个文件时，语义一致性的问题。规定了多进程如何同时访问共享文件，与同步算法相似，

Unix文件系统（UFS）语义：
- 对打开文件的写入内容立即对其他打开同一个文件的用户可见，
- 共享文件指针允许多个用户同时读取和写入文件。但是靠应用程序自己保证写入的完整性

会话语义只有当关闭文件时才能看到写入的文件。

## 目录、文件别名和文件系统种类
文件比较多时，需要引入文件系统，比如分层文件系统，把若干个文件以目录的形式组织起来，目录也是一种特殊的文件，这个特殊文件中存的内容是文件的索引表，一个索引是文件名+文件指针，这样就可以把文件系统组织成一颗树。早期的文件系统是扁平的，只有一层目录，现在可以组织成一颗很深的树。

用这种方式组织之后，需要在目录下进行额外的搜索，创建，删除等操作，对文件进行操作之后需要对目录进行相应的修改，操作系统应该只允许内核对目录进行修改，这样确保了映射的完整性，用户通过系统调用实现对目录的操作。

最简单的目录组织是线性表，但是如果检索和增删比较耗时；哈希表（哈希数据结构的线性表）可以减少目录搜索时间，且目录表中的每一项长度都相同。但是可能冲突，需要有相应解决。

如果两个或多个文件名关联同一个文件，本来是为了方便共享，但是需要特殊实现：
- 硬链接，多个文件项指向同一个文件，如果删除的时候把所有的链接都删了，那这个文件也就删了
- 软链接：以快捷方式的形式指向其他文件，通过存储真实文件的路径（逻辑名称）来实现。删除的时候文件不受影响，但删除了文件的话这个链接就失效了。

文件目录中的循环：父子文件目录相互指向，形成循环，需要保证不存在循环，一种是只允许到文件的链接，不允许在子目录的链接，另一种是增加链接时用循环检测算法进行检测，不过在实际系统中使用的是限制向下查找的深度。

名字解析：把逻辑名字转换成物理资源（如文件），给定路径，说明文件存在哪里并输出文件内容。遍历文件目录直到找到目标文件。读取根目录的文件头（在磁盘固定位置），读取目录的文件头及其数据块，继续搜索下一个目录，直到找到文件。

当前工作目录：每个进程都会指向一个文件目录用于解析文件名，这样就不用每次都从根目录下查找了

文件系统需要先挂载才能被访问，系统启动时，未被挂载的文件系统需要挂载到操作系统的根目录下。

文件系统种类：
- 磁盘文件系统：文件存储在数据存储设备中（如磁盘）。主要有FAT，NTFS，ext2/3，等。不同文件系统对文件的优化不同，安全要求级别也不同，访问效率也不同。
- 数据库文件系统：文件特征是可被检索的，如WinFS
- 日志文件系统：记录文件系统的修改和事件，对文件的操作是原子性的
- 网络/分布式文件系统：如NFS、SMB、AFS、GFS等，文件可以通过网络被共享，文件被存到远端的服务器上，客户端远程挂载服务器文件系统，标准文件访问被转换成网络远程访问。
    - 用户安全问题
    - 一致性问题
    - 错误处理模式问题

## 虚拟文件系统
操作系统希望对不同文件系统提供统一的接口，文件系统对上层应用提供统一的接口，下边对不同的文件系统提供相应的访问接口。虚拟文件系统的目的是对所有不同文件系统提供抽象，功能有：
- 提供相同的文件和文件系统接口
- 管理所有文件和文件系统关联的数据结构
- 提供高效查询例程，实现文件系统遍历
- 与特定文件系统模块交互

文件系统基本数据结构：
- 文件卷控制块
    - 每个文件系统一个
    - 文件系统的详细信息
    - 提供了块、块大小、空余块等信息
    - 文件系统挂载时进入内存
- 文件控制块（inode）：
    - 每个文件一个
    - 提供了文件的详细信息
    - 访问权限，拥有者，大小，数据块位置等
    - 访问文件时进入内存
- 目录项：
    - 每个目录项一个
    - 目录项数据结构及树形布局编码成树形数据结构
    - 指向文件控制块、父目录、子目录等。
    - 在遍历一个文件路径时加载

这些数据结构都是持久的存储在外存中的。

可以通过一个统一的接口访问各种各样的文件系统。

## 文件缓存和打开文件
文件缓存是指从磁盘读数据到CPU使用中间经过的缓存。磁盘控制器中有缓存，磁盘通过磁盘控制器完成数据的读写到内存和缓存，内存中有打开文件表，也有数据块缓存，从磁盘中读入数据块，数据块按需读入内存，也可采用“预读”机制提前读入。数据块也会在使用后被缓存，以防数据将会再次使用，写操作可能也会被缓存和延迟写入，这样可以将多次磁盘访问合并成一次，这存在写入失败和一致性的风险。

两种数据块缓存机制：
- 数据块缓存，每次读一个块时先看这个缓存中有没有。和虚拟存储隔离开。
- 页缓存：统一缓存数据块和内存页。把虚拟页面映射到外存文件中，也可把文件缓存到虚拟页中，文件读写转换成对内存的访问，可能导致缺页和设置成脏页。

文件系统中打开文件的数据结构：
- 文件描述符
    - 每个被打开的文件都有一个文件描述符
    - 保存了文件状态信息：目录项、当前文件指针等
- 打开文件表
    - 每个进程有一个打开文件表
    - 也有一个系统级的打开文件表
    - 有文件被打开的时候，文件卷就不能被卸载

打开一个文件时，目录项和文件信息都在内存中有缓存，系统打开文件表中有一部分是各个进程不一样的，这就组成了进程的打开文件表。

一些文件系统提供了文件锁，用于协调多进程的文件访问：
- 强制：根据锁保持情况和访问需求确定是否拒绝访问
- 劝告：进程可以根据锁的状态决定怎么做

## 文件分配
内存块分配给文件的情况与文件大小有关，文件系统需要对小文件提供很好的支持，且块空间不能过大。文件大小的分布有规律，大部分文件都很小，如果大部分文件存放在一个数据块里都有空闲，则这种分块方法是低效的。也有很大的文件，必须考虑如何支持大文件，表示文件使用n位，这个n与支持的最大的文件有关。

文件分配是指把哪些数据块分配给一个文件，即分配给一个文件数据块的位置和顺序。
- 连续分配：连续的一些块。文件头指定了起始块和长度。最先匹配，最佳匹配等。文件读取表现好，高效的顺序和随机访问。但是文件增长不方便，可以预分配或者按需分配。
- 链式分配：文件以数据库链表的方式存储。每个块中包含指向下一个块的指针。优点是创建、增大、缩小方便，且没有碎片，但是无法实现真正的随机访问，且破坏一个块，则后边的数据就都丢了。
- 索引分配：先分配一个索引块，说明哪些块里存了这个数据，即是指向文件数据块的指针列表。优点是创建、增大、缩小很简单，没有碎片，支持直接访问；但是文件很小到一个块就能存下时，这样就很浪费。文件比较大时需要多个索引块。

指标：
- 存储效率，第一种连续分配可能会存在外部碎片问题
- 读写性能，后两种可能在检索文件中间的内容的时候比较低效

UFS多级索引分配：
- 前边10个是直接索引
- 第11个是一级间接索引，这个块中保存了n个索引，每个索引指向一个块
- 第12个是二级间接索引，这个块中保存了n个一级索引
- 第13个是三级间接索引，这个块中保存了n个二级索引

效果：
- 提高了文件大小限制阈值
- 动态分配数据块，文件扩展简单
- 小文件开销小
-只为大文件分配间接数据块，大文件在访问时需要大量索引

## 空闲空间管理和冗余磁盘阵列RAID
空间空间管理需要记录或跟踪文件卷中未分配的数据块。

可以使用位图，Di=0表明数据块i是空闲的，否则是已分配的。这种方法使用简单但是可能是一个很大的向量表。
- 5M的位图表示40M数据块，表示了160G的磁盘。
- 假定空闲空间在磁盘中均匀分布，则找到0之前要扫描n/r，n是数据块总数，r是空闲块的数目

链式索引法：第一个块是空闲块的索引，指向空闲块。

通常磁盘通过分区来限制寻道时间，分区是一组柱面的集合，一个磁盘可以分成多个分区，每一个分区可以视为逻辑上独立的分区。如果只在一个分区上操作，那是可以提高性能的。

文件卷是一个拥有完整文件系统实例的空间，通常常驻在磁盘的单个分区上。

多磁盘可以改善吞吐量（通过并行），通过冗余提高可靠性和可用性。RAID（冗余磁盘阵列）是一组磁盘管理的技术，通过条带化、映像、带校验的条带化实现磁盘性能的提升。有两种实现：操作系统内核的文件卷管理或者硬件的RAID控制器。

RAID-0:磁盘条带化：把数据块分成若干个子块，存储在独立的磁盘上，通过独立磁盘的并行数据块访问提供更大的磁盘带宽，多个磁盘一起读取或写入一个文件的一部分。

RAID-1:磁盘镜像：像两个磁盘写入相同的数据，提高可靠性，从任何一个读取，可靠性成倍增加，读入性能线性增加。

RAID-4:带校验的磁盘条带化：数据块级的磁盘条带化加专用的奇偶校验磁盘，允许从任意一个故障磁盘中恢复数据。存校验和需要使用一个单独的校验磁盘，从之前的所有磁盘中读取数据进行校验和的计算。

RAID-5:分布式校验的磁盘条带化：不是把校验和固定存储在校验磁盘上，而是分开存放，提高校验和的读取性能。每组条带块有一个奇偶校验位，RAID-6中每组条带块有两个冗余块，允许两个磁盘块错误。

# 第二十二讲
## 总体介绍
操作系统提出了文件系统的抽象简化了对底层的访问。文件组织成目录，每一个目录项也是一个文件。文件和目录是应用程序看到的，索引节点是硬盘上的描述，安装点是一个访问文件系统包含文件的起始点。需要有针对这些抽象的操作，对于文件和目录，有open/close，read/write，对于索引节点，把磁盘中的数据和应用程序看到的文件建立对应关系，有lookup，安装点有mount和umount实现了对文件系统的挂载和卸载。

主要初始化的流程有：idle的初始化，init的初始化和文件系统磁盘外设的初始化，把文件系统的程序放到内存中来，变为进程在用户空间执行。virtual-system可以提供一个抽象，不管底层如何。

在lab5中，bootloader一开始就把应用程序加载到内存中来了，在lab8中通过文件系统执行。

在qemu模拟生成的硬盘上，有一个具体文件系统SFS，其上实现了一系列的层次，比如IO层次可以实现访问硬盘，通过simpleFS读取硬盘的结构，通过VFS给上层应用提供一致的接口，从而实现了syscall。

## ucore文件系统架构
首先，通用文件系统的访问接口为应用程序提供了API，放在了C库了，这个C库调用了系统调用，从而获得了ucore关于文件的服务，跳转到内核态中文件系统的相关实现。

接下来的控制交给了虚拟文件系统，包括了file接口，dir接口，inode接口，fs接口，外设接口，这个屏蔽了底层具体文件系统的差异性，比如，一个write函数会调用sys_write，接下来会访问sysfile_write、file_write、vop_write（面向用户的文件转换成面向文件系统的inode），这样转变成对inode的写操作，进一步转换成具体文件系统的inode的操作，即到了SimpleFS文件系统的实现。

在SimpleFS文件系统中，有sfs的inode实现和sfs的外设访问接口，调用sfs_write -> sfs_wbuf，数据内容就被写到了设备中。

通过上述的外设访问接口实现了对文件系统IO设备接口的访问，这个也是在硬盘上建立的抽象，在上层发起sfs_wbuf操作之后，把这个操作转换成针对devices的操作，有面向串口的、面向disk的、面向屏幕的，甚至面向NULL的。这层IO设备接口是抽象的接口，可以包含很多种类，比如，最终disk0会访问一个驱动，这个驱动是硬盘驱动，完成实际的硬盘读写。

在进程控制块中扩展了与文件相关的结构，files_struct* filesp，包括了打开文件指针集合。

## Simple FS分析
关注一个一般文件的读写。采用自下而上的方法，从硬盘到内存。

SimpleFS在文件系统的中间部分，主要内容存储在硬盘上，包括了superblock、root-dir inode、freemap等，SimpleFS被操作时，涉及了file、dir、inode、iobuffer等。

superblock是对SimpleFS整体描述，包括了标识magic_number，空闲了多少块，这些信息需要读入到内存中去，通过sfs_do_mount把文件系统加载到操作系统kernel中。紧接着在内存中建立一个Simple File System的整体框架：sfs_fs，在这个结构里，放入了之前所说的superblock的信息，这个文件系统所在的devices，freemap是这个文件系统中还有哪些空闲的数据块，一个bit表示一个空闲块，用一个hash或链表保存inode的情况。
```
struct sfs_fs{
    struct sfs_super super;
    struct device *dev;
    struct bitmap *freemap;
    void *sfs_buffer;
    list_entry_t inode_list;
}
```
在硬盘块上也有root-dir inode，表明了根目录信息，其中有直接索引和间接索引信息，表明了文件块在哪，通过inode的index可以查找数据块的位置。inode包含了两个层面的信息，第一个是在内存中，它有一个sfs_inode，第二个层面是在硬盘上有disk_inode，通过sfs_disk_inode完成进一步的对文件读写，

## Virtual FS分析
VFS在SimpleFS之上，应用程序之下，起到一个承上启下的作用，可以管理其他的设备和文件系统，也提供了统一接口供应用程序调用。在VFS建立与进程的联系，并与底层对接。一个数据结构file，提供了文件信息。通过file可以找到inode，实现对具体文件系统的映射。inode中有对这个inode的引用计数，针对一个inode有多少进程与之关联，换句话说，有多少进程打开了这个文件？
```
struct file{
    enum {
        FD_NONE, FD_INIT, FD_OPENED, FD_CLOSED
    } status;
    bool readable;
    bool writable;
    int fd;
    off_t pos;
    struct inode *node;
    atmoic_t open_count;
}
```
从进程角度而言，它需要知道打开了哪些文件，上边的fd代表了执行文件函数之后的返回值，也就是代表了这个文件，应用程序通过这个fd可以获取进一步的文件信息。

也有一个struct中包含了对文件的一些操作，有了这个接口实现了对设备的隔离，方便了应用程序对文件的操作。

## IO设备接口分析
IO接口在文件系统的底层，与具体文件系统和VFS有接口，也与底层的设备有接口。
IO设备数据结构如下，ioctl表示了通常读写之外的操作，
```
struct device{
    size_t d_blocks;
    size_t d_blocksize;
    int (*d_open);
    int (*d_close);
    int (*d_io);
    int (*d_ioctl);
}
```
启动中函数调用过程：kern_init -> fs_init -> dev_init -> dev_init_stdout -> dev_create_inode,stdout_device_init,vfs_add_dev，这样在vfs就可以访问设备了。

## 执行流程分析
在总控函数kern_init内增加了一个fs_init，在fs_init中实现了虚拟文件系统的初始化vfs_init，设备初始化dev_init，simple_fs的初始化sfs_init。

- 在vfs_init中，建立一个链表，针对dev的list，管理devices的fs；设置信号量对操作进行保护。
- 在dev_init中，初始化disk和stdin、stdout，分别代表了三类不同的设备。
- 在sfs_init中，最主要的是完成mount，加载这个文件系统。把sfs和vfs完成连接，


对一个文件，应用程序执行open，返回fd，代表了文件在文件列表中的位置，根据这个fd可以访问更详细的信息。open发出sys_open调用，发出syscall系统调用，操作系统进一步调用sys_open往下处理，把文件名的字符串向下传，分配一个fd_array的一项给他，把文件名实际对应的inode建立起来。vfs_open找到具体的文件系统，调用lookup查找函数，在simple_FS中递归查找一个文件对应的inode是多少，首先查找到目录的inode看目录项的文件名是不是跟要找的一致，如果一致就调用sfs_load_inode，再一层一层返回应用程序。

# 第二十三讲 I/O子系统
## 23.1 I/O特点
IO子系统是与外设交互的部分。三种常见的设备接口类型：
- 字符设备：以字节为单位顺序访问，每次只能一个字节输入，访问通常由get()，put()执行，使用文件访问接口和语义。
- 块设备：以均匀的数据块闻单位访问，访问通常使用原始IO或文件系统接口，内存映射文件访问。比如存储设备，磁盘磁带等
- 网络设备：格式化报文交换，IO命令是send/receive，通过网络接口支持多种网络协议。比如以太网、无线、蓝牙等。

同步与异步IO：用户发出IO请求，送入操作系统内核的设备驱动，设备驱动进行硬件控制数据传送。进行完之后，发出中断，返回进程。

阻塞IO：从发出请求到接收数据，进程需要等待。读数据时，进程进入等待状态，知道完成数据读出，写数据时，进程也进入等待，知道完成数据写入。

非阻塞IO：立即从read或write系统调用返回，返回值为成功传输字节数，read或write的传输字节数可能为0，这种方式可能不成功或者数据量与我们想的不一样。

异步IO：结合阻塞与非阻塞，读数据时，使用指针标记好缓冲区，立即返回，稍后操作系统将填充缓冲区并发出中断通知用户；写数据时，使用指针标记好缓冲区，立即返回。操作系统完成写入后将通知用户。

## 23.2 I/O结构
CPU为了与外界相连，北桥与显卡，内存相连，速度快，南桥与PCI总线等IO设备相连。设备上有IO控制器，提供了CPU和设备的接口，这里就是总线接口，然后有一组寄存器，可以进行数据交互，也可以映射到内存中，对内存的访问就是对IO设备的访问，这就是说的IO地址，它提供了一个内存映射的关系。

从设备到CPU：设备产生中断，在中断控制器进行汇总，CPU进行响应。

CPU和设备一共三种通信方式：
- 轮询：不用中断控制器，CPU直接访问IO端口或内存映射
- 设备中断：采用中断方式
- DMA：外部设备把数据直接放到内存单元

IO指令是通过IO端口号访问设备寄存器。在CPU执行out、in，对应了读写指令和设备控制。

内存映射IO是把设备的寄存器或存储映射到内存物理地址空间，通过内存load和store指令完成IO操作，由MMU设置映射。

每一个设备有对应的设备控制器，在这之上有驱动、IO子系统（请求转换，设备缓存）、内核。

IO请求生存周期：用户发出IO请求，操作系统中的IO子系统判断是否在缓存中有结果，如果有则直接返回，如果没有，给驱动发出IO请求，驱动转换成设备控制命令，等到硬件设备完成时，产生中断，由中断处理例程响应，保存结果并通知设备驱动层，把结果返回给IO子系统，最终返回给用户。

## 23.3 I/O数据传输
CPU和设备的数据传输有两种，一种是程序控制IO，通过CPU的in/out和load/store传输所有数据，硬件简单但是消耗的CPU时间与传输数据量成正比，适用于简单的小型IO。第二种是DMA，设备控制器直接访问系统总线，控制器直接访问内存，这样的话设备传输数据不影响CPU，但是需要CPU参与设置开始结束过程，适用于高吞吐量的IO。

直接IO寻址读取磁盘数据：产生磁盘读取请求，转到设备驱动在内核里执行，转换成对磁盘控制器的操作，磁盘开始读取数据，初始化DMA传送，磁盘控制器传送数据到DMA控制器，DMA控制器再把数据传输到指定的内存地址，完成传送后产生中断，CPU判断相应信息。

设备如何通知CPU：
- 轮询：IO设备在特定状态寄存器中放置了状态和错误信息，操作系统定期检测设备寄存器，简单但是IO操作频繁时开销大延时高。
- 设备中断：CPU在IO之前设置参数，由IO设备进行处理，处理完之后产生中断，CPU响应中断并调用中断处理例程响应，开销高。在高速设备中，第一次采用中断，之后采用轮询方式，有数据直接处理，直到硬件缓存为空。

中断IO的处理流程：产生IO请求，设备驱动初始化IO请求，IO控制器初始化IO操作，设备进行操作，操作完成或者出错产生中断，CPU每执行一条指令都会检查中断请求，如果有则转到中断处理，分发给中断处理例程，处理完之后CPU恢复被中断的进程的执行。

## 23.4 磁盘调度
读取或写入时，磁头被定位到期望的磁道，并从所期望的柱面和扇区开始，时间最长的是寻道时间，定位到期望的磁道。

平均旋转延迟时间=磁盘旋转一周时间的一半。

磁盘IO传输时间：等待设备可用、等待DMA通道或IO通道可用、寻道时间、旋转延时、数据传输的时间。

数据传输时间 = b/rN，b是传输的比特数，N是磁道上的比特数，r是磁盘的转数。

通过磁盘调度算法优化磁盘访问请求，提高磁盘访问性能，寻道时间是磁盘访问最耗时的部分。

先进先出：按照请求顺序处理，公平对待所有进程，接近随机访问的性能。

最短服务时间优先：选择从磁臂当前位置需要移动最少的IO请求，总是选择最短寻道时间。

扫描算法：磁臂在一个方向上移动，访问所有未完成的请求，直到磁臂到达该方向上最后的磁道，换方向之后再走到头。中间的磁道会更好，但是两边的磁道会访问时间长。

循环扫描算法：限制了仅在一个方向上扫描，当最后一个磁道也被访问过之后，磁臂返回到起点再次扫描。

C-Look：磁臂先到达该方向上最后一个请求的位置，然后立即反转，而不是到磁道的最后点路径。

N-step-SCAN：对付磁头黏着：可能出现磁头停留在某处不动的情况，只对该处的请求作出快速响应，比如进程反复请求对某一磁道的IO操作。将磁盘请求队列分成长度为N的子队列，按FIFO算法依次处理所有子队列，扫描算法处理每个队列。

双队列扫描：只把磁盘IO请求分成两个队列，交替使用扫描算法处理一个队列，新生成的磁盘IO请求放入另一个没有正在被处理的队列中，所有的新请求都被推迟到下一次扫描时处理。平均等待时间会减少。

## 23.5 磁盘缓存
双方访问速度大时，引入的速度匹配中间层。磁盘缓存是磁盘扇区在内存中的缓存区，磁盘缓存的调度算法类似虚拟存储调度算法。磁盘的访问频率远低于虚拟存储中的内存访问频率。

单缓存：设置一个缓冲区，一头是CPU一头是设备，设备开始写时CPU不能操作，CPU开始读时设备不能写，类似生产者消费者问题，只有一个能进行操作，限制了效率。

双缓存：IO设备向缓冲区1里写数据的同时，CPU从缓冲区2中读取数据，完成之后交换。

访问频率置换算法：在一段密集磁盘访问后，LFU算法的引用计数无法反映当前的引用情况。这种算法考虑了磁盘访问的密集特性，对密集引用不做计数，在短周期中使用LRU算法，在长周期中使用LFU。

